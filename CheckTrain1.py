# Check.py - ç³»ç»Ÿæ€§é—®é¢˜æ’æŸ¥å·¥å…·
import torch
import torch.nn as nn
import pandas as pd
import numpy as np
from torch.utils.data import DataLoader
import sys
import os
from torch.utils.data import Dataset

print("=" * 60)
print("ğŸ” æ™ºèƒ½é‹å«é¡¹ç›® - ç³»ç»Ÿé—®é¢˜æ’æŸ¥å·¥å…·")
print("=" * 60)

# ==================== 1. ç¯å¢ƒæ£€æŸ¥ ====================
print("\n1. ğŸ› ï¸ ç¯å¢ƒæ£€æŸ¥")
print(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
print(f"CUDAå¯ç”¨: {torch.cuda.is_available()}")
if torch.cuda.is_available():
    print(f"GPUè®¾å¤‡: {torch.cuda.get_device_name(0)}")
    print(f"CUDAç‰ˆæœ¬: {torch.version.cuda}")

# ==================== 2. æ•°æ®æ£€æŸ¥ ====================
print("\n2. ğŸ“Š æ•°æ®å®Œæ•´æ€§æ£€æŸ¥")

class DataChecker:
    def __init__(self, csv_path):
        self.csv_path = csv_path
        self.data = None
        
    def load_and_check(self):
        print(f"æ£€æŸ¥æ–‡ä»¶: {self.csv_path}")
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(self.csv_path):
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {self.csv_path}")
            return False
        
        try:
            # åŠ è½½æ•°æ®
            self.data = pd.read_csv(self.csv_path)
            print(f"âœ… æ–‡ä»¶åŠ è½½æˆåŠŸï¼Œå½¢çŠ¶: {self.data.shape}")
            
            # æ£€æŸ¥åŸºæœ¬åˆ—
            required_columns = ['Fx_norm', 'Fy_norm', 'Fz_norm']
            for col in required_columns:
                if col not in self.data.columns:
                    print(f"âŒ ç¼ºå¤±å¿…è¦åˆ—: {col}")
                    return False
            
            print(f"âœ… å¿…è¦åˆ—æ£€æŸ¥é€šè¿‡")
            return True
            
        except Exception as e:
            print(f"âŒ æ–‡ä»¶è¯»å–å¤±è´¥: {e}")
            return False
    
    def analyze_data(self):
        if self.data is None:
            return
        
        print(f"\n  æ•°æ®è¯¦æƒ…:")
        print(f"    æ€»è¡Œæ•°: {len(self.data)}")
        print(f"    æ€»åˆ—æ•°: {len(self.data.columns)}")
        
        # æ£€æŸ¥CapSenseåˆ— (0-17)
        capsense_cols = [f'ele_{i}' for i in range(18)]
        capsense_missing = [col for col in capsense_cols if col not in self.data.columns]
        if capsense_missing:
            print(f"  âš ï¸  ç¼ºå¤±CapSenseåˆ—: {capsense_missing[:5]}...")
        else:
            print(f"  âœ… CapSenseåˆ—å®Œæ•´ (0-17)")
        
        # æ£€æŸ¥IMUåˆ— (18-24)
        imu_cols = [f'ele_{i}' for i in range(18, 25)]
        imu_missing = [col for col in imu_cols if col not in self.data.columns]
        if imu_missing:
            print(f"  âš ï¸  ç¼ºå¤±IMUåˆ—: {imu_missing}")
        else:
            print(f"  âœ… IMUåˆ—å®Œæ•´ (18-24)")
        
        # æ£€æŸ¥NaNå€¼
        nan_counts = self.data.isna().sum()
        total_nan = nan_counts.sum()
        print(f"  NaNå€¼æ€»æ•°: {total_nan}")
        
        if total_nan > 0:
            print(f"  âš ï¸  åŒ…å«NaNçš„åˆ—:")
            for col, count in nan_counts.items():
                if count > 0:
                    print(f"    {col}: {count}ä¸ªNaN ({count/len(self.data)*100:.2f}%)")
        
        # æ£€æŸ¥æ— ç©·å€¼
        inf_cols = []
        for col in self.data.select_dtypes(include=[np.number]).columns:
            if np.any(np.isinf(self.data[col].values)):
                inf_cols.append(col)
        
        if inf_cols:
            print(f"  âŒ åŒ…å«æ— ç©·å€¼çš„åˆ—: {inf_cols}")
        else:
            print(f"  âœ… æ— æ— ç©·å€¼")
        
        # æ£€æŸ¥æ•°æ®èŒƒå›´
        print(f"\n  æ•°æ®èŒƒå›´æ£€æŸ¥:")
        
        # CapSenseèŒƒå›´
        capsense_data = self.data[[f'ele_{i}' for i in range(18)]].values
        print(f"    CapSenseèŒƒå›´: {capsense_data.min():.2f} ~ {capsense_data.max():.2f}")
        print(f"    CapSenseå‡å€¼: {capsense_data.mean():.2f} Â± {capsense_data.std():.2f}")
        
        # IMUèŒƒå›´
        imu_data = self.data[[f'ele_{i}' for i in range(18, 25)]].values
        print(f"    IMUèŒƒå›´: {imu_data.min():.2f} ~ {imu_data.max():.2f}")
        print(f"    IMUå‡å€¼: {imu_data.mean():.2f} Â± {imu_data.std():.2f}")
        
        # æ ‡ç­¾èŒƒå›´
        labels = self.data[['Fx_norm', 'Fy_norm', 'Fz_norm']].values
        print(f"    æ ‡ç­¾èŒƒå›´: {labels.min():.2f} ~ {labels.max():.2f}")
        print(f"    æ ‡ç­¾å‡å€¼: {labels.mean():.2f} Â± {labels.std():.2f}")

# æµ‹è¯•æ•°æ®æ–‡ä»¶
test_file = "D:/TG0/PublicData_Rep/Smart_Insole_Database/subject_1/squatting_s1_merged.csv"
checker = DataChecker(test_file)

if checker.load_and_check():
    checker.analyze_data()
else:
    print("âŒ æ•°æ®æ£€æŸ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶è·¯å¾„")
    sys.exit(1)

# ==================== 3. æ¨¡å‹ç»„ä»¶æ£€æŸ¥ ====================
print("\n3. ğŸ¤– æ¨¡å‹ç»„ä»¶æ£€æŸ¥")

def test_dense_block():
    print("  æµ‹è¯•DenseBlockå®ç°...")
    
    class SimpleDenseBlock(nn.Module):
        def __init__(self, input_dim, output_dim=32):
            super().__init__()
            self.fc1 = nn.Linear(input_dim, output_dim)
            self.fc2 = nn.Linear(output_dim, output_dim)
            self.relu = nn.ReLU()
        
        def forward(self, x):
            x = self.relu(self.fc1(x))
            x = self.relu(self.fc2(x))
            return x
    
    # æµ‹è¯•
    block = SimpleDenseBlock(18, 32)
    test_input = torch.randn(32, 18)
    output = block(test_input)
    
    print(f"   è¾“å…¥: {test_input.shape}")
    print(f"   è¾“å‡º: {output.shape}")
    print(f"   è¾“å‡ºèŒƒå›´: {output.min():.3f} ~ {output.max():.3f}")
    print(f"   âœ… DenseBlockæµ‹è¯•é€šè¿‡")

def test_cross_attention():
    print("  æµ‹è¯•CrossAttentionå®ç°...")
    
    class SimpleCrossAttention(nn.Module):
        def __init__(self, dim=32):
            super().__init__()
            self.q_proj = nn.Linear(dim, dim)
            self.k_proj = nn.Linear(dim, dim)
            self.v_proj = nn.Linear(dim, dim)
        
        def forward(self, query, key, dim):
            Q = self.q_proj(query)
            K = self.k_proj(key)
            V = self.v_proj(value)
            
            attention = torch.softmax(torch.matmul(Q, K.transpose(-2, -1)) / (dim ** 0.5), dim=-1)
            output = torch.matmul(attention, V)
            return output
    
    # æµ‹è¯•
    attention = SimpleCrossAttention(32)
    query = torch.randn(32, 32)
    key = torch.randn(32, 32)
    value = torch.randn(32, 32)
    
    output = attention(query, key, value)
    
    print(f"   Query: {query.shape}")
    print(f"   Output: {output.shape}")
    print(f"   âœ… CrossAttentionæµ‹è¯•é€šè¿‡")

# è¿è¡Œç»„ä»¶æµ‹è¯•
test_dense_block()
test_cross_attention()

# ==================== 4. è®­ç»ƒæµç¨‹æ£€æŸ¥ ====================
print("\n4. ğŸ”„ è®­ç»ƒæµç¨‹æ£€æŸ¥")

def test_training_flow():
    print("  æµ‹è¯•æœ€å°è®­ç»ƒæµç¨‹...")
    
    # æœ€å°æ•°æ®é›†
    class MiniDataset:
        def __init__(self):
            self.capsense = torch.randn(100, 18)
            self.imu = torch.randn(100, 7)
            self.labels = torch.randn(100, 3)
        
        def __len__(self):
            return 100
        
        def __getitem__(self, idx):
            return self.capsense[idx], self.imu[idx], self.labels[idx]
    
    # æœ€å°æ¨¡å‹
    class MiniModel(nn.Module):
        def __init__(self):
            super().__init__()
            self.cap_fc = nn.Linear(18, 16)
            self.imu_fc = nn.Linear(7, 16)
            self.fusion = nn.Linear(32, 3)
        
        def forward(self, cap, imu):
            cap_out = torch.relu(self.cap_fc(cap))
            imu_out = torch.relu(self.imu_fc(imu))
            combined = torch.cat([cap_out, imu_out], dim=1)
            return self.fusion(combined)
    
    # æµ‹è¯•è®­ç»ƒ
    dataset = MiniDataset()
    dataloader = DataLoader(dataset, batch_size=32, shuffle=True)
    model = MiniModel()
    criterion = nn.MSELoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
    
    # ä¸€ä¸ªepochçš„è®­ç»ƒ
    model.train()
    total_loss = 0
    for batch_idx, (cap, imu, labels) in enumerate(dataloader):
        optimizer.zero_grad()
        outputs = model(cap, imu)
        loss = criterion(outputs, labels)
        
        # æ£€æŸ¥æŸå¤±æ˜¯å¦ä¸ºnan
        if torch.isnan(loss):
            print(f"  âŒ ç¬¬{batch_idx}æ‰¹æ¬¡æŸå¤±ä¸ºnan!")
            break
        
        loss.backward()
        optimizer.step()
        total_loss += loss.item()
    
    avg_loss = total_loss / (batch_idx + 1)
    print(f"  å¹³å‡æŸå¤±: {avg_loss:.6f}")
    
    if not torch.isnan(torch.tensor(avg_loss)):
        print(f"  âœ… è®­ç»ƒæµç¨‹æµ‹è¯•é€šè¿‡")
    else:
        print(f"  âŒ è®­ç»ƒæµç¨‹å­˜åœ¨é—®é¢˜")

test_training_flow()

# ==================== 5. é—®é¢˜è¯Šæ–­å»ºè®® ====================
print("\n5. ğŸ’¡ é—®é¢˜è¯Šæ–­å»ºè®®")

print("""
æ ¹æ®ä½ çš„è®­ç»ƒè¾“å‡ºï¼Œå‘ç°ä»¥ä¸‹é—®é¢˜ï¼š

ğŸ”´ ä¸»è¦é—®é¢˜ï¼šæŸå¤±å€¼ä¸ºnan

å¯èƒ½åŸå› åŠè§£å†³æ–¹æ¡ˆï¼š

1. ğŸ“Š æ•°æ®é—®é¢˜
   - æ£€æŸ¥æ•°æ®ä¸­æ˜¯å¦æœ‰NaNæˆ–æ— ç©·å€¼
   - æ£€æŸ¥æ•°æ®èŒƒå›´æ˜¯å¦å¼‚å¸¸
   - ç¡®ä¿æ•°æ®å·²æ­£ç¡®æ ‡å‡†åŒ–

2. ğŸ—ï¸ æ¨¡å‹æ¶æ„é—®é¢˜
   - DenseBlockè¾“å‡ºç»´åº¦ä¸ä¸€è‡´ï¼ˆ114 vs 115ï¼‰
   - äº¤å‰æ³¨æ„åŠ›ç»´åº¦ä¸åŒ¹é…
   - æ¢¯åº¦çˆ†ç‚¸ï¼ˆæ•°å€¼è¿‡å¤§ï¼‰

3. âš™ï¸ è®­ç»ƒé…ç½®é—®é¢˜
   - å­¦ä¹ ç‡å¯èƒ½è¿‡é«˜
   - æ²¡æœ‰æ¢¯åº¦è£å‰ª
   - æƒé‡åˆå§‹åŒ–é—®é¢˜

å»ºè®®æ“ä½œé¡ºåºï¼š
1. å…ˆè¿è¡Œæœ¬æ£€æŸ¥è„šæœ¬ç¡®è®¤æ•°æ®è´¨é‡
2. ä½¿ç”¨ç®€å•æ¨¡å‹ç¡®ä¿åŸºç¡€æµç¨‹èƒ½è·‘é€š
3. é€æ­¥å¢åŠ å¤æ‚åº¦
4. æ·»åŠ æ¢¯åº¦ç›‘æ§å’Œæ•°å€¼ç¨³å®šæ€§æ£€æŸ¥
""")

print("\n" + "=" * 60)
print("âœ… æ£€æŸ¥å®Œæˆï¼è¯·æ ¹æ®ä»¥ä¸Šå»ºè®®è¿›è¡Œä¿®å¤")
print("=" * 60)


