# fix_walking_s5_encoding.py
import pandas as pd
import chardet
import os

file_path = r"D:\TG0\PublicData_Rep\Smart_Insole_Database\subject_5\walking_s5_merged.csv"

def detect_encoding(file_path):
    """æ£€æµ‹æ–‡ä»¶ç¼–ç """
    with open(file_path, 'rb') as f:
        raw_data = f.read(10000)  # è¯»å–å‰10000å­—èŠ‚æ£€æµ‹ç¼–ç 
        result = chardet.detect(raw_data)
        return result['encoding'], result['confidence']

def fix_csv_encoding(file_path):
    """ä¿®å¤CSVæ–‡ä»¶ç¼–ç å’Œæ ¼å¼é—®é¢˜"""
    print(f"æ­£åœ¨ä¿®å¤æ–‡ä»¶: {os.path.basename(file_path)}")
    
    # 1. æ£€æµ‹ç¼–ç 
    encoding, confidence = detect_encoding(file_path)
    print(f"æ£€æµ‹åˆ°ç¼–ç : {encoding} (ç½®ä¿¡åº¦: {confidence:.2%})")
    
    # 2. å°è¯•ç”¨ä¸åŒç¼–ç è¯»å–
    encodings_to_try = [
        'utf-8', 'gbk', 'gb2312', 'gb18030', 
        'latin1', 'iso-8859-1', 'cp1252'
    ]
    
    if encoding and encoding.lower() not in [e.lower() for e in encodings_to_try]:
        encodings_to_try.insert(0, encoding)
    
    df = None
    successful_encoding = None
    
    for enc in encodings_to_try:
        try:
            print(f"å°è¯•ä½¿ç”¨ {enc} ç¼–ç è¯»å–...")
            df = pd.read_csv(file_path, encoding=enc, on_bad_lines='skip')
            print(f"âœ“ ä½¿ç”¨ {enc} ç¼–ç æˆåŠŸè¯»å–")
            print(f"  æ•°æ®å½¢çŠ¶: {df.shape}")
            print(f"  åˆ—æ•°: {len(df.columns)}")
            successful_encoding = enc
            break
        except Exception as e:
            print(f"  âœ— {enc} å¤±è´¥: {str(e)[:100]}")
    
    if df is None:
        print("âŒ æ‰€æœ‰ç¼–ç éƒ½å¤±è´¥äº†ï¼Œå°è¯•åŸå§‹äºŒè¿›åˆ¶è¯»å–...")
        try:
            # ä½¿ç”¨æ›´ä½çº§çš„è¯»å–æ–¹å¼
            with open(file_path, 'rb') as f:
                lines = f.readlines()
            
            # è½¬æ¢ä¸ºutf-8ï¼Œå¿½ç•¥é”™è¯¯
            utf8_lines = []
            for i, line in enumerate(lines):
                try:
                    utf8_lines.append(line.decode('utf-8'))
                except:
                    try:
                        utf8_lines.append(line.decode('gbk', errors='ignore'))
                    except:
                        # å¦‚æœè¿˜æ˜¯å¤±è´¥ï¼Œè·³è¿‡è¿™ä¸€è¡Œ
                        print(f"è·³è¿‡ç¬¬{i+1}è¡Œï¼ˆæ— æ³•è§£ç ï¼‰")
            
            # å†™å…¥ä¸´æ—¶æ–‡ä»¶
            temp_file = file_path.replace('.csv', '_temp_fixed.csv')
            with open(temp_file, 'w', encoding='utf-8') as f:
                f.writelines(utf8_lines)
            
            # é‡æ–°è¯»å–
            df = pd.read_csv(temp_file, on_bad_lines='skip')
            os.remove(temp_file)  # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            
        except Exception as e:
            print(f"âŒ äºŒè¿›åˆ¶è¯»å–ä¹Ÿå¤±è´¥: {e}")
            return None
    
    # 3. æ£€æŸ¥æ•°æ®è´¨é‡
    print("\nğŸ“Š æ•°æ®è´¨é‡æ£€æŸ¥:")
    print(f"  æ€»è¡Œæ•°: {len(df)}")
    print(f"  æ€»åˆ—æ•°: {len(df.columns)}")
    print(f"  ç¼ºå¤±å€¼æ€»æ•°: {df.isnull().sum().sum()}")
    
    # æ˜¾ç¤ºåˆ—å
    print(f"\nğŸ“‹ åˆ—ååˆ—è¡¨:")
    for i, col in enumerate(df.columns, 1):
        print(f"  {i:2d}. {col}")
    
    # 4. æ£€æŸ¥æ˜¯å¦æœ‰ ele_36 åˆ—
    if 'ele_36' in df.columns:
        print(f"\nâœ… æ‰¾åˆ° ele_36 åˆ—ï¼ˆå³è„šæ•°æ®æ ‡è¯†ï¼‰")
        right_foot_count = (df['ele_36'] == 0).sum()
        print(f"  å³è„šæ•°æ®è¡Œæ•° (ele_36==0): {right_foot_count:,}")
    else:
        print(f"\nâš ï¸  è­¦å‘Š: æ²¡æœ‰æ‰¾åˆ° ele_36 åˆ—")
        # å°è¯•æŸ¥æ‰¾ç±»ä¼¼çš„åˆ—å
        potential_cols = [col for col in df.columns if '36' in str(col) or 'ele' in str(col).lower()]
        if potential_cols:
            print(f"  å¯èƒ½çš„æ›¿ä»£åˆ—: {potential_cols}")
    
    # 5. ä¿å­˜ä¿®å¤åçš„æ–‡ä»¶
    fixed_file = file_path.replace('.csv', '_fixed.csv')
    try:
        df.to_csv(fixed_file, index=False, encoding='utf-8')
        print(f"\nğŸ’¾ ä¿®å¤åçš„æ–‡ä»¶å·²ä¿å­˜åˆ°: {fixed_file}")
        
        # éªŒè¯ä¿å­˜çš„æ–‡ä»¶
        try:
            df_check = pd.read_csv(fixed_file)
            print(f"âœ… éªŒè¯é€šè¿‡: ä¿®å¤æ–‡ä»¶å¯ä»¥æ­£å¸¸è¯»å–ï¼Œå½¢çŠ¶: {df_check.shape}")
            return fixed_file
        except Exception as e:
            print(f"âŒ éªŒè¯å¤±è´¥: {e}")
            return None
            
    except Exception as e:
        print(f"âŒ ä¿å­˜å¤±è´¥: {e}")
        return None
    
    return df

def process_with_dataextract(fixed_file):
    """ä½¿ç”¨ä½ çš„Dataextract.pyå¤„ç†ä¿®å¤åçš„æ–‡ä»¶"""
    print("\nğŸ”„ ä½¿ç”¨Dataextract.pyå¤„ç†ä¿®å¤åçš„æ–‡ä»¶...")
    
    try:
        from Dataextract import extract_right_foot_data
        
        output_folder = r"D:\TG0\PublicData_Rep\Smart_Insole_Database\subjectRepro5"
        
        result = extract_right_foot_data(
            csv_path=fixed_file,
            save_extracted=True,
            output_folder=output_folder
        )
        
        if result is not None:
            print("âœ… Dataextractå¤„ç†æˆåŠŸï¼")
            return True
        else:
            print("âŒ Dataextractè¿”å›None")
            return False
            
    except Exception as e:
        print(f"âŒ Dataextractå¤„ç†å¤±è´¥: {e}")
        return False

def main():
    print("="*60)
    print("ğŸ› ï¸  CSVæ–‡ä»¶ä¿®å¤å·¥å…· - walking_s5_merged.csv")
    print("="*60)
    
    if not os.path.exists(file_path):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        return
    
    # ä¿®å¤æ–‡ä»¶
    fixed_file = fix_csv_encoding(file_path)
    
    if fixed_file:
        print("\n" + "="*60)
        print("ğŸ¯ ç°åœ¨å¯ä»¥:")
        print("1. ç”¨ä¿®å¤åçš„æ–‡ä»¶é‡æ–°è¿è¡Œæ‰¹å¤„ç†")
        print(f"2. æˆ–è€…ç›´æ¥å¤„ç†: {fixed_file}")
        print("="*60)
        
        # è¯¢é—®æ˜¯å¦ç»§ç»­å¤„ç†
        response = input("\næ˜¯å¦ç”¨Dataextract.pyå¤„ç†ä¿®å¤åçš„æ–‡ä»¶? (y/n): ")
        if response.lower() == 'y':
            process_with_dataextract(fixed_file)
    else:
        print("\nâŒ æ–‡ä»¶ä¿®å¤å¤±è´¥ï¼Œå¯èƒ½éœ€è¦æ‰‹åŠ¨æ£€æŸ¥æ–‡ä»¶å†…å®¹ã€‚")

if __name__ == "__main__":
    main()