import pandas as pd
import numpy as np
import os

def extract_right_foot_data(csv_path, save_extracted=True, output_folder="subjectRepro1"):
    """
    ä»åŸå§‹CSVæ–‡ä»¶ä¸­æå–å³è„šæ•°æ®ç”¨äºè®ºæ–‡æ¨¡å‹è®­ç»ƒ
    
    å‚æ•°:
        csv_path: åŸå§‹CSVæ–‡ä»¶è·¯å¾„
        save_extracted: æ˜¯å¦ä¿å­˜æå–åçš„æ•°æ®
        output_folder: è¾“å‡ºæ–‡ä»¶å¤¹åç§°
    
    è¿”å›:
        df_extracted: æå–åçš„DataFrame
    """
    
    print(f"æ­£åœ¨æå–æ•°æ®: {os.path.basename(csv_path)}")
    
    # 1. è¯»å–CSVæ–‡ä»¶
    df = pd.read_csv(csv_path)
    
    print(f"åŸå§‹æ•°æ®å½¢çŠ¶: {df.shape}")
    print(f"æ€»è¡Œæ•°: {len(df)}")
    
    # 2. åªé€‰æ‹©å³è„šæ•°æ® (ele_36 == 0)
    df_right = df[df['ele_36'] == 0].copy()
    print(f"å³è„šæ•°æ®è¡Œæ•° (ele_36==0): {len(df_right)}")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å³è„šæ•°æ®
    if len(df_right) == 0:
        print("è­¦å‘Š: æ²¡æœ‰æ‰¾åˆ°å³è„šæ•°æ® (ele_36==0)")
        return None
    
    # 3. åˆ›å»ºé‡å‘½åæ˜ å°„å­—å…¸
    rename_dict = {
        # æ—¶é—´æˆ³
        'timestamp': 'timestamp',
        
        # å³è„šCapSense (0-11)
        'ele_0': 'C0', 'ele_1': 'C1', 'ele_2': 'C2', 'ele_3': 'C3',
        'ele_4': 'C4', 'ele_5': 'C5', 'ele_6': 'C6', 'ele_7': 'C7',
        'ele_8': 'C8', 'ele_9': 'C9', 'ele_10': 'C10', 'ele_11': 'C11',
        
        # åŠ é€Ÿåº¦è®¡ (18-20)
        'ele_18': 'Ax', 'ele_19': 'Ay', 'ele_20': 'Az',
        
        # é™€èºä»ª (22-24) - åŒ…æ‹¬Yawï¼Œä½†è®ºæ–‡ä¸ç”¨
        'ele_22': 'Gr',  # Roll
        'ele_23': 'Gp',  # Pitch
        'ele_24': 'Gy',  # Yaw (æå–ä½†ä¸ä½¿ç”¨)
        
        # GRFæ ‡ç­¾ (å·²ç”¨ä½“é‡æ ‡å‡†åŒ–)
        'Fx_norm': 'Fx_norm',
        'Fy_norm': 'Fy_norm',
        'Fz_norm': 'Fz_norm'
    }
    
    # 4. æå–éœ€è¦çš„åˆ—
    columns_to_extract = list(rename_dict.keys())
    df_extracted = df_right[columns_to_extract].copy()
    
    # 5. é‡å‘½ååˆ—
    df_extracted = df_extracted.rename(columns=rename_dict)
    
    # 6. é‡ç½®ç´¢å¼•
    df_extracted = df_extracted.reset_index(drop=True)
    
    # 7. æ£€æŸ¥ç¼ºå¤±å€¼
    missing_count = df_extracted.isnull().sum().sum()
    if missing_count > 0:
        print(f"è­¦å‘Š: å‘ç° {missing_count} ä¸ªç¼ºå¤±å€¼ï¼Œå°†è¿›è¡Œå‰å‘å¡«å……")
        df_extracted = df_extracted.fillna(method='ffill').fillna(method='bfill')
    
    # 8. éªŒè¯æå–ç»“æœ
    print(f"\næå–åçš„æ•°æ®å½¢çŠ¶: {df_extracted.shape}")
    print(f"æå–çš„åˆ—æ•°: {len(df_extracted.columns)}")
    
    # 9. æ˜¾ç¤ºæ•°æ®èŒƒå›´ï¼ˆç”¨äºåç»­å½’ä¸€åŒ–å‚è€ƒï¼‰
    print("\næ•°æ®èŒƒå›´:")
    print("=" * 50)
    
    # CapSenseèŒƒå›´
    capsense_cols = [f'C{i}' for i in range(12)]
    capsense_min = df_extracted[capsense_cols].min().min()
    capsense_max = df_extracted[capsense_cols].max().max()
    print(f"å³è„šCapSenseèŒƒå›´: [{capsense_min:.1f}, {capsense_max:.1f}] (è®ºæ–‡èŒƒå›´: 0-800)")
    
    # åŠ é€Ÿåº¦è®¡èŒƒå›´
    acc_cols = ['Ax', 'Ay', 'Az']
    acc_min = df_extracted[acc_cols].min().min()
    acc_max = df_extracted[acc_cols].max().max()
    print(f"åŠ é€Ÿåº¦è®¡èŒƒå›´: [{acc_min:.2f}, {acc_max:.2f}] (è®ºæ–‡èŒƒå›´: -1åˆ°1)")
    
    # é™€èºä»ªèŒƒå›´
    gyro_cols = ['Gr', 'Gp', 'Gy']
    gyro_min = df_extracted[gyro_cols].min().min()
    gyro_max = df_extracted[gyro_cols].max().max()
    print(f"é™€èºä»ªèŒƒå›´: [{gyro_min:.1f}, {gyro_max:.1f}] (è®ºæ–‡èŒƒå›´: -600åˆ°600)")
    
    # GRFèŒƒå›´
    grf_cols = ['Fx_norm', 'Fy_norm', 'Fz_norm']
    grf_min = df_extracted[grf_cols].min().min()
    grf_max = df_extracted[grf_cols].max().max()
    print(f"GRF(å·²é™¤ä½“é‡)èŒƒå›´: [{grf_min:.3f}, {grf_max:.3f}]")
    
    # 10. ä¿å­˜æå–åçš„æ•°æ®
    if save_extracted:
        # åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤¹
        os.makedirs(output_folder, exist_ok=True)
        
        # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
        base_name = os.path.basename(csv_path).replace('.csv', '')
        output_filename = f"{base_name}_extracted_right_foot.csv"
        output_path = os.path.join(output_folder, output_filename)
        
        # ä¿å­˜åˆ°CSV
        df_extracted.to_csv(output_path, index=False)
        print(f"\næå–çš„æ•°æ®å·²ä¿å­˜åˆ°: {output_path}")
        
        # ä¹Ÿä¿å­˜ä¸€ä¸ªç”¨äºæ¨¡å‹è®­ç»ƒçš„ç‰ˆæœ¬ï¼ˆåªåŒ…å«17ä¸ªç‰¹å¾+3ä¸ªæ ‡ç­¾ï¼‰
        model_cols = (
            ['timestamp'] + 
            [f'C{i}' for i in range(12)] +  # 12ä¸ªCapSense
            ['Ax', 'Ay', 'Az'] +            # 3ä¸ªåŠ é€Ÿåº¦è®¡
            ['Gr', 'Gp'] +                  # 2ä¸ªé™€èºä»ªï¼ˆRollå’ŒPitchï¼‰
            ['Fx_norm', 'Fy_norm', 'Fz_norm']  # 3ä¸ªGRFæ ‡ç­¾
        )
        
        df_model = df_extracted[model_cols].copy()
        model_filename = f"{base_name}_model_ready.csv"
        model_path = os.path.join(output_folder, model_filename)
        df_model.to_csv(model_path, index=False)
        print(f"æ¨¡å‹è®­ç»ƒæ•°æ®å·²ä¿å­˜åˆ°: {model_path}")
        
        # æ‰“å°æ¨¡å‹æ•°æ®ä¿¡æ¯
        print(f"\næ¨¡å‹è®­ç»ƒæ•°æ®å½¢çŠ¶: {df_model.shape}")
        print(f"æ¨¡å‹è®­ç»ƒæ•°æ®åˆ—: {df_model.columns.tolist()}")
    
    # 11. è¿”å›æå–çš„æ•°æ®
    return df_extracted

def batch_extract_data(csv_folder_path, output_folder="subjectRepro1"):
    """
    æ‰¹é‡æå–æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰CSVæ–‡ä»¶
    """
    if not os.path.exists(csv_folder_path):
        print(f"æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {csv_folder_path}")
        return
    
    # åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤¹
    os.makedirs(output_folder, exist_ok=True)
    
    all_extracted = []
    all_model_ready = []
    
    for file_name in os.listdir(csv_folder_path):
        if file_name.endswith('.csv'):
            csv_path = os.path.join(csv_folder_path, file_name)
            print("\n" + "="*60)
            
            try:
                df_extracted = extract_right_foot_data(csv_path, save_extracted=True, output_folder=output_folder)
                
                if df_extracted is not None:
                    # æ·»åŠ æ–‡ä»¶åæ ‡è¯†åˆ—
                    df_extracted['source_file'] = file_name
                    all_extracted.append(df_extracted)
                    
                    # åˆ›å»ºæ¨¡å‹è®­ç»ƒæ•°æ®
                    model_cols = (
                        ['timestamp'] + 
                        [f'C{i}' for i in range(12)] +
                        ['Ax', 'Ay', 'Az'] +
                        ['Gr', 'Gp'] +
                        ['Fx_norm', 'Fy_norm', 'Fz_norm'] +
                        ['source_file']
                    )
                    df_model = df_extracted[model_cols].copy()
                    all_model_ready.append(df_model)
                    
            except Exception as e:
                print(f"å¤„ç†æ–‡ä»¶ {file_name} æ—¶å‡ºé”™: {e}")
    
    # åˆå¹¶æ‰€æœ‰æå–çš„æ•°æ®
    if all_extracted:
        # åˆå¹¶å®Œæ•´æå–çš„æ•°æ®
        combined_df = pd.concat(all_extracted, ignore_index=True)
        combined_path = os.path.join(output_folder, "all_extracted_data.csv")
        combined_df.to_csv(combined_path, index=False)
        print(f"\næ‰€æœ‰æå–çš„æ•°æ®å·²åˆå¹¶ä¿å­˜åˆ°: {combined_path}")
        print(f"åˆå¹¶åçš„æ€»æ ·æœ¬æ•°: {len(combined_df)}")
        
        # åˆå¹¶æ¨¡å‹è®­ç»ƒæ•°æ®
        if all_model_ready:
            combined_model_df = pd.concat(all_model_ready, ignore_index=True)
            combined_model_path = os.path.join(output_folder, "all_model_ready_data.csv")
            combined_model_df.to_csv(combined_model_path, index=False)
            print(f"æ‰€æœ‰æ¨¡å‹è®­ç»ƒæ•°æ®å·²åˆå¹¶ä¿å­˜åˆ°: {combined_model_path}")
            print(f"æ¨¡å‹è®­ç»ƒæ•°æ®æ€»æ ·æœ¬æ•°: {len(combined_model_df)}")
            print(f"æ¨¡å‹è®­ç»ƒæ•°æ®åˆ—æ•°: {len(combined_model_df.columns)}")
            
            # æ‰“å°ç‰¹å¾å’Œæ ‡ç­¾ä¿¡æ¯
            feature_cols = [f'C{i}' for i in range(12)] + ['Ax', 'Ay', 'Az'] + ['Gr', 'Gp']
            label_cols = ['Fx_norm', 'Fy_norm', 'Fz_norm']
            print(f"\nç‰¹å¾åˆ—æ•°: {len(feature_cols)}")
            print(f"æ ‡ç­¾åˆ—æ•°: {len(label_cols)}")
        
        return combined_df
    
    return None

def create_model_ready_data(df_extracted):
    """
    ä»æå–çš„æ•°æ®åˆ›å»ºæ¨¡å‹è®­ç»ƒæ‰€éœ€çš„Xå’Œy
    """
    if df_extracted is None:
        print("æ²¡æœ‰æå–çš„æ•°æ®å¯ç”¨")
        return None, None, None, None
    
    # è®ºæ–‡ä½¿ç”¨çš„ç‰¹å¾ï¼šå³è„šCapSense(12) + åŠ é€Ÿåº¦è®¡(3) + é™€èºä»ª(2) = 17ç»´
    # æ³¨æ„ï¼šè®ºæ–‡åªç”¨äº†é™€èºä»ªçš„Rollå’ŒPitchï¼Œä¸ç”¨Yaw
    
    # ç‰¹å¾åˆ—
    feature_cols = (
        [f'C{i}' for i in range(12)] +  # å³è„šCapSense
        ['Ax', 'Ay', 'Az'] +            # åŠ é€Ÿåº¦è®¡
        ['Gr', 'Gp']                    # é™€èºä»ª (åªç”¨Rollå’ŒPitch)
    )
    
    # æ ‡ç­¾åˆ— (GRF)
    label_cols = ['Fx_norm', 'Fy_norm', 'Fz_norm']
    
    # æå–ç‰¹å¾å’Œæ ‡ç­¾
    X = df_extracted[feature_cols].values
    y = df_extracted[label_cols].values
    
    print(f"\næ¨¡å‹è®­ç»ƒæ•°æ®å‡†å¤‡å®Œæˆ:")
    print(f"ç‰¹å¾Xå½¢çŠ¶: {X.shape} (æ ·æœ¬æ•°Ã—{len(feature_cols)})")
    print(f"æ ‡ç­¾yå½¢çŠ¶: {y.shape} (æ ·æœ¬æ•°Ã—{len(label_cols)})")
    
    # ç‰¹å¾æè¿°
    print(f"\nä½¿ç”¨çš„ç‰¹å¾ ({len(feature_cols)}ä¸ª):")
    for i, col in enumerate(feature_cols, 1):
        print(f"{i:2d}. {col}")
    
    return X, y, feature_cols, label_cols

# ==================== ä½¿ç”¨ç¤ºä¾‹ ====================

# ç¤ºä¾‹1: æå–å•ä¸ªæ–‡ä»¶
if __name__ == "__main__":
    # åŸå§‹æ•°æ®è·¯å¾„
    csv_file = "Smart_Insole_Database/subject_1/jogging_s1_merged.csv"
    
    # è¾“å‡ºæ–‡ä»¶å¤¹çš„å®Œæ•´è·¯å¾„
    output_dir = r"D:\TG0\PublicData_Rep\Smart_Insole_Database\subjectRepro1"
    
    # è¾“å‡ºæ–‡ä»¶å
    output_filename = "jogging_s1_merged.csv"
    model_filename = "jogging_s1_model_ready.csv"
    
    # å®Œæ•´çš„è¾“å‡ºè·¯å¾„
    output_path = os.path.join(output_dir, output_filename)
    model_data_path = os.path.join(output_dir, model_filename)
    
    print("="*60)
    print(f"å¼€å§‹æå–æ•°æ®å¹¶ä¿å­˜åˆ°: {output_dir}")
    print("="*60)
    
    # æå–å•ä¸ªæ–‡ä»¶ï¼ˆä¸è‡ªåŠ¨ä¿å­˜ï¼Œæˆ‘ä»¬æ‰‹åŠ¨ä¿å­˜ï¼‰
    df_extracted = extract_right_foot_data(
        csv_file, 
        save_extracted=False,  # å…³é”®ï¼šè®¾ä¸ºFalseï¼Œæˆ‘ä»¬æ‰‹åŠ¨ä¿å­˜
        output_folder=output_dir
    )
    
    if df_extracted is not None:
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(output_dir, exist_ok=True)
        
        # 1. ä¿å­˜å®Œæ•´æå–æ•°æ®åˆ°æŒ‡å®šè·¯å¾„
        df_extracted.to_csv(output_path, index=False)
        print(f"\nâœ… å®Œæ•´æå–æ•°æ®å·²ä¿å­˜åˆ°: {output_path}")
        
        # 2. åˆ›å»ºæ¨¡å‹è®­ç»ƒæ•°æ®
        X, y, feature_cols, label_cols = create_model_ready_data(df_extracted)
        
        # 3. åˆ›å»ºæ¨¡å‹è®­ç»ƒæ•°æ®DataFrameå¹¶ä¿å­˜
        model_cols = ['timestamp'] + feature_cols + label_cols
        df_model = df_extracted[model_cols].copy()
        df_model.to_csv(model_data_path, index=False)
        print(f"âœ… æ¨¡å‹è®­ç»ƒæ•°æ®å·²ä¿å­˜åˆ°: {model_data_path}")
        
        # 4. æ˜¾ç¤ºå‰å‡ ä¸ªæ ·æœ¬
        print("\n" + "="*60)
        print("æ•°æ®æ ·æœ¬é¢„è§ˆ:")
        print("="*60)
        print("\nå‰3ä¸ªæ ·æœ¬çš„ç‰¹å¾å€¼ (å‰5ä¸ªç‰¹å¾):")
        print(X[:3, :5])
        
        print("\nå‰3ä¸ªæ ·æœ¬çš„æ ‡ç­¾å€¼:")
        print(y[:3])
        
        # 5. æ˜¾ç¤ºæ–‡ä»¶ä¿å­˜ä¿¡æ¯
        print("\n" + "="*60)
        print("æ–‡ä»¶ä¿å­˜ä½ç½®:")
        print("="*60)
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
        print(f"ğŸ“„ å®Œæ•´æå–æ•°æ®: {output_filename} ({df_extracted.shape[0]}è¡ŒÃ—{df_extracted.shape[1]}åˆ—)")
        print(f"ğŸ¤– æ¨¡å‹è®­ç»ƒæ•°æ®: {model_filename} ({df_model.shape[0]}è¡ŒÃ—{df_model.shape[1]}åˆ—)")
        
        print(f"\nğŸ“Š æ•°æ®ç»Ÿè®¡:")
        print(f"  æ€»æ ·æœ¬æ•°: {df_extracted.shape[0]}")
        print(f"  ç‰¹å¾æ•°é‡: {len(feature_cols)}")
        print(f"  æ ‡ç­¾æ•°é‡: {len(label_cols)}")
        print(f"  ç‰¹å¾åˆ—: {feature_cols}")
        print(f"  æ ‡ç­¾åˆ—: {label_cols}")
    # ç¤ºä¾‹2: æ‰¹é‡æå–æ•´ä¸ªæ–‡ä»¶å¤¹
    # print("\n" + "="*60)
    # print("æ‰¹é‡æå–æ–‡ä»¶å¤¹ä¸­æ‰€æœ‰CSVæ–‡ä»¶")
    # print("="*60)
    # csv_folder = "your_dataset_folder"  # æ›¿æ¢ä¸ºä½ çš„æ–‡ä»¶å¤¹è·¯å¾„
    # batch_extract_data(csv_folder, output_folder="subjectRepro1")